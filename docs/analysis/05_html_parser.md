# 模块分析: HTML 解析器 (htmls.py)

本模块是一个**非标准**的 HTML 解析器，它不构建 DOM 树，而是基于**正则表达式**和**字符串索引**来定位和操作 HTML 标签。

## 文件信息
*   **路径**: `dict2anki/htmls.py`
*   **主要职责**: 查找标签位置、提取标签内容、替换标签、删除标签。
*   **设计初衷**: 避免引入重量级的 `BeautifulSoup` 或 `lxml`，保持零依赖。

## 核心原理
该模块的核心假设是 HTML 标签是成对出现的（尽管 HTML 规范允许某些标签不成对，但本工具主要处理结构良好的词典页面）。

### 1. `find_positions(html_str, tag, attrib)`
这是所有操作的基础生成器。
*   **输入**: HTML 字符串，标签名 (如 `div`), 属性筛选串 (如 `class="di-body"`)。
*   **逻辑**:
    1.  构造正则匹配开始标签 (`<tag...>`) 和结束标签 (`</tag>`)。
    2.  遍历所有匹配项。
    3.  维护一个计数器 `count`：遇到开始标签 +1，遇到结束标签 -1。
    4.  当 `count` 从 0 变为 1 且匹配到指定的 `attrib` 时，记录 `start` 索引。
    5.  当 `count` 回归 0 时，记录 `end` 索引，并 yield `(start, end)`。
*   **局限性**: 这种基于计数的方法可以处理嵌套标签（例如 `div` 里面套 `div`），但对于自闭合标签或错误的 HTML 结构可能极其脆弱。

### 2. `sub(html_str, replace, tag, attrib)`
通用替换函数。
*   调用 `find_positions` 获取所有匹配的 `(start, end)` 索引对。
*   倒序遍历索引对（从后往前替换，以免破坏前面的索引位置）。
*   对切片内容调用 `replace` 回调函数，拼接新字符串。

### 3. `removeall(html_str, tag, attrib)`
基于 `sub` 的快捷方式。
*   `replace` 函数简单地返回空字符串 `''`。

### 4. `find` / `findall`
基于 `find_positions` 提取字符串切片。

## 优缺点分析

| 特性 | 说明 |
| :--- | :--- |
| **优点** | 1. **零依赖**: 纯 Python 标准库实现。<br>2. **轻量**: 无需构建庞大的 DOM 树，内存占用低。 |
| **缺点** | 1. **脆弱**: 极其依赖 HTML 的规范性。如果剑桥词典的 HTML 变得不规范（如属性顺序变化、空格变化），正则匹配 `attrib` 就会失败。<br>2. **性能**: 对于深层嵌套或大文件，正则查找和字符串拼接可能不如优化的 C 扩展库快（虽然对于单词卡片这个量级通常不是瓶颈）。<br>3. **维护**: 正则表达式难以阅读和调试。 |

## 重写建议
在重写时，强烈建议引入 `BeautifulSoup4` 或 `lxml`。虽然增加了依赖，但能极大提高代码的可读性、鲁棒性和解析的灵活性（例如支持 CSS 选择器）。现有的 `htmls.py` 是为了“零依赖”这一特定目标而存在的妥协方案。
